import streamlit as st
import re
import time
import json
import requests
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS  # è¿½åŠ : æ¤œç´¢ç”¨

# ==========================================
# âš™ï¸ Configuration & Constants
# ==========================================

CANDIDATE_MODELS = [
    "gpt-4o-mini",      # ã€ãŠã™ã™ã‚ã€‘ã‚³ã‚¹ãƒ‘æœ€å¼·
    "gpt-4o",           # ã€æœ€å¼·ã€‘ç²¾åº¦é‡è¦–
    "gpt-4-turbo"
]

# ==========================================
# ğŸ› ï¸ Helper Functions (Web Search & Context)
# ==========================================

def search_movie_context(movie_title):
    """
    æ˜ ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰è„šæœ¬ã‚„ã‚ã‚‰ã™ã˜ã‚’æ¤œç´¢ã—ã€ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹
    """
    # æ¤œç´¢ã‚¯ã‚¨ãƒª: ã‚¿ã‚¤ãƒˆãƒ« + script/synopsis/transcript
    query = f"{movie_title} movie script transcript synopsis characters plot"
    
    try:
        # DuckDuckGoã§æ¤œç´¢ (ä¸Šä½3ä»¶)
        results = DDGS().text(query, max_results=3)
        if not results:
            return None
            
        combined_text = ""
        # æ¤œç´¢çµæœã®URLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆç°¡æ˜“ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
        for res in results:
            url = res['href']
            try:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ã‚ã«è¨­å®šã—ã¦å–å¾—
                page = requests.get(url, timeout=3)
                if page.status_code == 200:
                    soup = BeautifulSoup(page.content, 'html.parser')
                    # <p>ã‚¿ã‚°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é›†ã‚ã‚‹ï¼ˆæœ¬æ–‡ã®å¯èƒ½æ€§ãŒé«˜ã„ãŸã‚ï¼‰
                    paragraphs = [p.get_text() for p in soup.find_all('p')]
                    # æœ€åˆã®3000æ–‡å­—ç¨‹åº¦ã‚’å–å¾—ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ï¼‰
                    text_content = " ".join(paragraphs)[:3000]
                    combined_text += f"\n--- Source: {url} ---\n{text_content}\n"
            except:
                continue
        
        return combined_text if combined_text else None
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneã‚’è¿”ã—ã¦ç¿»è¨³å‡¦ç†è‡ªä½“ã¯æ­¢ã‚ãªã„
        print(f"Search Error: {e}")
        return None

def generate_style_guide(api_key, movie_title, raw_web_text):
    """
    Webã®æƒ…å ±ã‚’åŸºã«ã€ç¿»è¨³ç”¨ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ï¼ˆè¨­å®šè³‡æ–™ï¼‰ã‚’AIã«ä½œæˆã•ã›ã‚‹
    """
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    # æŒ‡ç¤ºæ›¸ä½œæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = f"""
    You are an expert movie localization director.
    Read the provided web content about the movie "{movie_title}".
    Create a concise "Translation Style Guide" for Japanese subtitles.
    
    Output Format:
    - **Genre & Tone**: (e.g., Serious, Slang-heavy, Historical, Comedy)
    - **Key Characters & Relationships**: (Who is talking to whom? e.g., "Jack and Rose are lovers", "Boss and subordinate")
    - **Speaking Style**: (e.g., "Use polite Desu/Masu", "Use rough Yakuza slang", "Old Samurai dialect")
    - **Plot Summary**: (Very brief summary to understand context)
    """

    data = {
        "model": "gpt-4o-mini", # å®‰ä¾¡ãªãƒ¢ãƒ‡ãƒ«ã§ååˆ†
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Web Content:\n{raw_web_text}"}
        ]
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=20)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
    except:
        pass
    return None

# ==========================================
# ğŸ› ï¸ Core Functions
# ==========================================

def find_working_model(api_key, log_area):
    headers = {'Content-Type': 'application/json', 'Authorization': f'Bearer {api_key}'}
    test_data = {"model": "gpt-4o-mini", "messages": [{"role": "user", "content": "Test"}], "max_tokens": 5}
    log_area.text(f"ğŸ‘‰ Testing API connection...")
    try:
        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, data=json.dumps(test_data), timeout=10)
        if response.status_code == 200:
            log_area.success(f"âœ… Connection successful!")
            return True
        else:
            st.warning(f"âš ï¸ Connection failed (Status: {response.status_code})")
            return False
    except Exception as e:
        st.error(f"ğŸ“¡ Connection Error: {str(e)}")
        return False

def split_srt_blocks(srt_content):
    content = srt_content.replace('\r\n', '\n').replace('\r', '\n')
    blocks = re.split(r'\n\s*\n', content.strip())
    return [b for b in blocks if b.strip()]

def sanitize_timecode(time_str):
    t = re.sub(r'\s*[-=]+>\s*', ' --> ', time_str)
    return t.replace('.', ',')

def translate_block_openai(text, api_key, model_name, movie_title, target_language, style_guide=None, previous_context=None):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    # æ–‡è„ˆæƒ…å ±ã®æ§‹ç¯‰
    context_str = ""
    if style_guide:
        context_str += f"[MOVIE SETTING]\n{style_guide}\n\n"
    
    if previous_context:
        context_str += f"[PREVIOUS CONVERSATION]\n{previous_context}\n(Use this to understand the flow, but DO NOT translate these lines.)\n\n"

    system_prompt = f"""
    You are a professional subtitle translator for the movie "{movie_title}".
    Translate the [CURRENT LINE] into natural {target_language}.

    Guidelines:
    1. **Context Aware**: Look at [PREVIOUS CONVERSATION] to determine omitted subjects (who is "I", "You", "He"?) and the correct nuance.
       - Example: If previous line is "You are talented", "It's natural" -> "ç”Ÿã¾ã‚Œã¤ãã•" (Not "è‡ªç„¶ä½“").
    2. **Character Tone**: Reflect the character's personality defined in [MOVIE SETTING].
    3. **Format**: Output ONLY the translated text for [CURRENT LINE]. No quotes, no notes.
    """
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"[CURRENT LINE]\n{text}"}
    ]
    
    data = {
        "model": model_name,
        "messages": messages,
        "temperature": 0.3
    }

    # ãƒªãƒˆãƒ©ã‚¤å‡¦ç†ãªã©ã¯æ—¢å­˜ã¨åŒã˜
    for attempt in range(3):
        try:
            response = requests.post(url, headers=headers, data=json.dumps(data), timeout=60)
            if response.status_code == 200:
                content = response.json()['choices'][0]['message']['content'].strip()
                return content if content else text
            elif response.status_code == 429:
                time.sleep(5)
                continue
            else:
                time.sleep(1)
                continue
        except:
            time.sleep(1)
            continue
    return text

# ==========================================
# ğŸ–¥ï¸ Streamlit Screen Layout
# ==========================================

def main():
    st.set_page_config(page_title="AI Subtitle Translator + Web Context", layout="wide")
    st.title("ğŸ¬ AI Subtitles Translator (ChatGPT)")

    with st.sidebar:
        st.header("Settings")
        api_key_input = st.text_input("OpenAI API Key", type="password")
        selected_model = st.selectbox("Select Model", CANDIDATE_MODELS, index=0)
        st.markdown("---")
        
        # æ˜ ç”»ã‚¿ã‚¤ãƒˆãƒ«å…¥åŠ›ï¼ˆæ¤œç´¢ã«å¿…é ˆï¼‰
        movie_title_input = st.text_input("Movie Title (Required for Context)", help="æ­£ç¢ºã«å…¥åŠ›ã™ã‚‹ã¨æ¤œç´¢ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™")
        target_lang_input = st.text_input("Target Language", value="Japanese")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢æ©Ÿèƒ½ã®ON/OFF
        use_context = st.checkbox("ğŸ” Search Web for Context", value=True, help="ãƒãƒƒãƒˆã‹ã‚‰è„šæœ¬ã‚„ã‚ã‚‰ã™ã˜ã‚’æ¢ã—ã¦ç¿»è¨³ç²¾åº¦ã‚’ä¸Šã’ã¾ã™")

    uploaded_file = st.file_uploader("Upload SRT file", type=["srt"])

    if uploaded_file is not None and st.button("Start Translation", type="primary"):
        if not api_key_input:
            st.error("âš ï¸ API Key is missing.")
            return
        if use_context and not movie_title_input:
            st.warning("âš ï¸ To use Web Search, please enter the 'Movie Title'.")
            return

        status_area = st.empty()
        log_area = st.empty()
        context_expander = st.expander("ğŸ“š Generated Style Guide (Context)", expanded=False)
        progress_bar = st.progress(0)

        if find_working_model(api_key_input, log_area):
            
            # --- PHASE 1: Web Context Search & Analysis ---
            style_guide = None
            if use_context:
                status_area.info(f"ğŸŒ Searching web for info about '{movie_title_input}'...")
                
                # 1. æ¤œç´¢ & ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
                raw_web_data = search_movie_context(movie_title_input)
                
                if raw_web_data:
                    status_area.info("ğŸ“ Generating style guide from web data...")
                    # 2. æƒ…å ±ã‚’è¦ç´„ã—ã¦ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰ä½œæˆ
                    style_guide = generate_style_guide(api_key_input, movie_title_input, raw_web_data)
                    
                    if style_guide:
                        context_expander.markdown(style_guide) # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¦‹ãˆã‚‹ã‚ˆã†ã«è¡¨ç¤º
                        st.toast("Style Guide Created Successfully!", icon="âœ…")
                    else:
                        st.warning("Could not generate style guide.")
                else:
                    st.warning("No relevant info found on the web. Proceeding without context.")
            
            # --- PHASE 2: Translation ---
            content = uploaded_file.getvalue().decode("utf-8", errors="ignore")
            blocks = split_srt_blocks(content)
            total_blocks = len(blocks)
            translated_srt = []
            
            # â˜…è¿½åŠ : ç›´å‰ã®ä¼šè©±ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆï¼ˆãƒãƒƒãƒ•ã‚¡ï¼‰
            conversation_history = [] 
            
            status_area.info(f"ğŸš€ Translating {total_blocks} blocks with Context Flow...")
            
            for i, block in enumerate(blocks):
                lines = block.split('\n')
                if len(lines) >= 2:
                    time_line_index = -1
                    for idx, line in enumerate(lines):
                        if '-->' in line:
                            time_line_index = idx
                            break
                    
                    if time_line_index != -1:
                        seq_num = lines[0]
                        timecode = lines[time_line_index]
                        original_text = "\n".join(lines[time_line_index + 1:])
                        
                        if original_text.strip():
                            # â˜…å¤‰æ›´: ç›´è¿‘3ä»¶ã®å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦æ¸¡ã™
                            previous_context_str = "\n".join(conversation_history[-3:]) # ç›´å‰3ãƒ–ãƒ­ãƒƒã‚¯åˆ†
                            
                            translated_text = translate_block_openai(
                                original_text, 
                                api_key_input, 
                                selected_model, 
                                movie_title_input, 
                                target_lang_input,
                                style_guide=style_guide,
                                previous_context=previous_context_str # â˜…ã“ã“ã§éå»ã®æ–‡è„ˆã‚’æ¸¡ã™
                            )
                            
                            # â˜…è¿½åŠ : ç¿»è¨³ã«ä½¿ã£ãŸåŸæ–‡ã‚’å±¥æ­´ã«è¿½åŠ 
                            # (æ”¹è¡Œã‚’é™¤å»ã—ã¦1è¡Œã«ã—ã¦ä¿å­˜ã™ã‚‹ã¨èª­ã¿ã‚„ã™ã„)
                            clean_original = original_text.replace('\n', ' ')
                            conversation_history.append(clean_original)
                            
                        else:
                            translated_text = ""
                        
                        clean_time = sanitize_timecode(timecode)
                        new_block = f"{seq_num}\r\n{clean_time}\r\n{translated_text}\r\n\r\n"
                        translated_srt.append(new_block)
                    else:
                        translated_srt.append(block + "\r\n\r\n")
                else:
                    translated_srt.append(block + "\r\n\r\n")
                
                # --- ä»¥ä¸‹ã€é€²æ—ãƒãƒ¼ãªã©ã®æ—¢å­˜ã‚³ãƒ¼ãƒ‰ ---
                progress = (i + 1) / total_blocks
                progress_bar.progress(progress)
                if (i + 1) % 5 == 0:
                    log_area.text(f"â³ Processing... {i + 1}/{total_blocks}")
                time.sleep(0.05)

            progress_bar.progress(1.0)
            status_area.success("âœ… Complete!")
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            final_content = "".join(translated_srt)
            new_filename = f"{uploaded_file.name.replace('.srt', '')}_AI_WebContext.srt"
            
            st.download_button(
                label="ğŸ“¥ Download Translated SRT",
                data=final_content.encode('utf-8-sig'),
                file_name=new_filename,
                mime="text/plain"
            )

if __name__ == "__main__":
    main()